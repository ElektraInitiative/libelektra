/* https://build.libelektra.org/jenkins/job/elektra-jenkinsfile/
 * This file describes how the elektra-jenkinsfile buildjob should be
 * executed.
 *
 * 1. imports and global variables are set
 * 2. define the main stages of the pipeline
 * 3. describe sub stages. This is where you will want to add new builds
 * 4. helper section to help write build scripts
 *
 * General Information about Jenkinsfiles can be found at
 * https://jenkins.io/doc/book/pipeline/jenkinsfile/.
 *
 * A Snippet generator is available to the public at
 * https://qa.nuxeo.org/jenkins/pipeline-syntax/.
 * A list of available commands on the build server can be found after a login at
 * https://build.libelektra.org/jenkins/job/elektra-jenkinsfile/pipeline-syntax/.
 */

// FIXME sloc publish errors
// XXX add missing jobs
// TODO have a per plugin/binding deps in Dockerfile for easier maintenance
// TODO add warnings plugins to scan for compiler warnings
// TODO maybe intend with 2 lines to not waste so much ws

// Imports
import java.text.SimpleDateFormat

// Buildjob properties
properties([
    buildDiscarder(logRotator(numToKeepStr: '60', artifactNumToKeepStr: '60'))
])

// Globals
docker_node_label = 'docker'
registry = 'hub.libelektra.org'

/* Define reusable cmake Flag globals
 *
 * They can be passed to many of the test helper functions and the cmake
 * function and represent flags usually passed to cmake.
 */
CMAKE_FLAGS_BASE = [
    'SITE': '${STAGE_NAME}',
    'KDB_DB_SYSTEM': '${HOME}/.config/kdb/system',
    'KDB_DB_SPEC': '${HOME}/.config/kdb/spec',
    'CMAKE_INSTALL_PREFIX': '${WORKSPACE}/system',
    'INSTALL_SYSTEM_FILES': 'OFF',
    'BUILD_DOCUMENTATION': 'OFF'
]

// TODO Remove -DEPRECATED after #1954 is resolved
CMAKE_FLAGS_BUILD_ALL = [
    'BINDINGS': 'ALL;-DEPRECATED',
    'PLUGINS': 'ALL;-DEPRECATED',
    'TOOLS': 'ALL'
]

CMAKE_FLAGS_COVERAGE = ['ENABLE_COVERAGE': 'ON']

CMAKE_FLAGS_CLANG = [
    'CMAKE_C_COMPILER': 'clang-5.0',
    'CMAKE_CXX_COMPILER': 'clang++-5.0'
]

CMAKE_FLAGS_ASAN = ['ENABLE_ASAN': 'ON']
CMAKE_FLAGS_DEBUG = ['ENABLE_DEBUG': 'ON']
CMAKE_FLAGS_LOGGER = ['ENABLE_LOGGER': 'ON']

// Define TEST enum used in buildAndTest helper
enum TEST {
    MEM, NOKDB, ALL, INSTALL
    public TEST() {}  // WORKAROUND https://issues.jenkins-ci.org/browse/JENKINS-33023
}

// Define DOCKER_OPTS enum which is used in withDockerEnv
enum DOCKER_OPTS {
    MOUNT_MIRROR, PTRACE
    public DOCKER_OPTS() {} // WORKAROUND see TEST
}

NOW = new Date()
DOCKER_IMAGES = [:]

// If previous run is still running, cancel it
abortPreviousRun()

/*****************************************************************************
 * Main Stages
 *
 * Serial stages that contain parallelized logic. Only proceeds to the next
 * if previous stage did not fail.
 *****************************************************************************/

stage("Init docker images") {
    dockerInit()
}

IMAGES_TO_BUILD = false
stage("Pull docker images") {
    parallel generateDockerPullStages()
}

maybeStage("Build docker images", IMAGES_TO_BUILD) {
    lock('docker-images') {
        parallel generateDockerBuildStages()
    }
}

stage("Main builds") {
    milestone label: "Main builds"
    parallel generateMainBuildStages()
}

stage("Full builds") {
    milestone label: "Full builds"
    parallel generateFullBuildStages()
}

maybeStage("Build artifacts", isMaster()) {
    milestone label: "artifacts"
    parallel generateArtifactStages()
}

maybeStage("Deploy Homepage", isMaster()) {
    deployHomepage()
}

/*****************************************************************************
 * Stage Generators
 *****************************************************************************/

/* Populate DOCKER_IMAGES with data
 *
 * For this we need a checkout of the scm to generate the hash for the
 * Dockerfiles which indicates if a rebuild of the images is needed
 */
def dockerInit() {
    node("master") {
        echo "Processing DOCKER_IMAGES"
        checkout scm
        DOCKER_IMAGES.sid = createDockerImageDesc(
            "debian-sid", this.&idTesting,
            "./scripts/docker/debian/sid",
            "./scripts/docker/debian/sid/Dockerfile"
        )
        DOCKER_IMAGES.stretch = createDockerImageDesc(
            "debian-stretch", this.&idTesting,
            "./scripts/docker/debian/stretch",
            "./scripts/docker/debian/stretch/Dockerfile"
        )
        DOCKER_IMAGES.stretch_minimal = createDockerImageDesc(
            "debian-stretch-minimal", this.&idTesting,
            "./scripts/docker/debian/stretch",
            "./scripts/docker/debian/stretch/Dockerfile.minimal"
        )
        DOCKER_IMAGES.stretch_doc = createDockerImageDesc(
            "debian-stretch-doc", this.&idTesting,
            "./scripts/docker/debian/stretch",
            "./scripts/docker/debian/stretch/Dockerfile.doc"
        )
        DOCKER_IMAGES.jessie = createDockerImageDesc(
            "debian-jessie", this.&idTesting,
            "./scripts/docker/debian/jessie",
            "./scripts/docker/debian/jessie/Dockerfile"
        )
        DOCKER_IMAGES.xenial = createDockerImageDesc(
            "ubuntu-xenial", this.&idTesting,
            "./scripts/docker/ubuntu/xenial",
            "./scripts/docker/ubuntu/xenial/Dockerfile"
        )
        DOCKER_IMAGES.homepage_frontend = createDockerImageDesc(
            "homepage-frontend", this.&idHomepage,
            ".",
            "./scripts/docker/homepage/frontend/Dockerfile",
            false
        )
        DOCKER_IMAGES.homepage_frontend = createDockerImageDesc(
            "homepage-backend", this.&idHomepage,
            ".",
            "./scripts/docker/homepage/backend/Dockerfile",
            false
        )
    }
}

/* Generate Stages to pull all docker images */
def generateDockerPullStages() {
    def tasks = [:]
    DOCKER_IMAGES.each { key, image ->
        if(image.autobuild) {
            tasks << pullImageStage(image)
        }
    }
    return tasks
}

/* Returns a stage that tries to pull an image
 *
 * Also sets IMAGES_TO_BUILD to true if an image can not be found
 * to indicated that rebuilds are needed
 * @param image Map identifying which image to pull
 */
def pullImageStage(image) {
    def taskname = "pull/${image.id}/"
    return [(taskname): {
        stage(taskname) {
            node(docker_node_label) {
                echo "Starting ${env.STAGE_NAME} on ${env.NODE_NAME}"
                docker.withRegistry("https://${registry}",
                                    'docker-hub-elektra-jenkins') {
                    try {
                        docker.image(image.id).pull()
                        echo "Found existing image"
                        image.exists = true
                    } catch(e) {
                        echo "Detected changes"
                        image.exists = false
                        IMAGES_TO_BUILD = true
                    }
                }
            }
        }
    }]
}

def generateDockerBuildStages() {
    def tasks = [:]
    DOCKER_IMAGES.each { key, image ->
        if(image.autobuild && !image.exists) {
            tasks << buildImageStage(image)
        }
    }
    return tasks
}

/* Returns a map with a closure that builds image
 *
 * @param image Image that needs to be build
 */
def buildImageStage(image) {
    def taskname = "build/${image.id}/"
    return [(taskname): {
        stage(taskname) {
            node(docker_node_label) {
                echo "Starting ${env.STAGE_NAME} on ${env.NODE_NAME}"
                docker.withRegistry("https://${registry}",
                                    'docker-hub-elektra-jenkins') {
                    checkout scm
                    def uid = getUid()
                    def gid = getGid()
                    def cpu_count = cpuCount()
                    def i = docker.build(
                        image.id,"""\
--pull \
--build-arg JENKINS_GROUPID=${gid} \
--build-arg JENKINS_USERID=${uid} \
--build-arg PARALLEL=${cpu_count} \
-f ${image.file} ${image.context}"""
                    )
                    i.push()
                }
            }
        }
    }]
}

/* Generate Main stages
 *
 * Should be used to give quick feedback to developer and check for obvious
 * errors before the intensive tasks start
 */
def generateMainBuildStages() {
    def tasks = [:]
    tasks << buildAndTest(
        "debian-stable-full",
        DOCKER_IMAGES.stretch,
        CMAKE_FLAGS_BUILD_ALL +
            CMAKE_FLAGS_COVERAGE,
        [TEST.ALL, TEST.MEM, TEST.INSTALL]
    )
    tasks << buildIcheck()
    tasks << buildCheckReleaseNotes()
    return tasks
}

/* Generate Test stages for full test coverage
 */
def generateFullBuildStages() {
    def tasks = [:]
    tasks << buildTodo()
    tasks << buildDoc()
    tasks << buildAndTestAsan(
        "debian-stable-asan",
        DOCKER_IMAGES.stretch,
        CMAKE_FLAGS_BUILD_ALL
    )
    tasks << buildAndTestAsan(
        "debian-unstable-clang-asan",
        DOCKER_IMAGES.sid,
        CMAKE_FLAGS_BUILD_ALL +
            CMAKE_FLAGS_CLANG
    )
    tasks << buildAndTest(
        "debian-oldstable-full",
        DOCKER_IMAGES.jessie,
        CMAKE_FLAGS_BUILD_ALL,
        [TEST.ALL, TEST.MEM, TEST.INSTALL]
    )
    tasks << buildAndTest(
        "debian-unstable-full",
        DOCKER_IMAGES.sid,
        CMAKE_FLAGS_BUILD_ALL,
        [TEST.ALL, TEST.MEM, TEST.INSTALL]
    )
    tasks << buildAndTest(
        "debian-unstable-full-clang",
        DOCKER_IMAGES.sid,
        CMAKE_FLAGS_BUILD_ALL +
            CMAKE_FLAGS_CLANG,
        [TEST.ALL, TEST.MEM, TEST.INSTALL]
    )
    tasks << buildAndTest(
        "ubuntu-xenial",
        DOCKER_IMAGES.xenial,
        CMAKE_FLAGS_BUILD_ALL,
        [TEST.ALL]
    )
    tasks << buildAndTest(
        "debian-stable-minimal",
        DOCKER_IMAGES.stretch_minimal,
        [:],
        [TEST.ALL]
    )
    return tasks
}

def buildTodo() {
    def stage_name = "todo"
    def open_task_patterns = '''\
**/*.c, **/*.h, **/*.hpp, **/*.cpp,\
**/CMakeLists.txt, **/Dockerfile*, Jenkinsfile*
'''
    return [(stage_name): {
        stage(stage_name) {
            withDockerEnv(DOCKER_IMAGES.stretch_doc) {
                sh "sloccount --duplicates --wide --details ${WORKSPACE} > sloccount.sc"
                step([$class: 'SloccountPublisher', ignoreBuildFailure: true])
                openTasks pattern: open_task_patterns,
                          high: 'XXX',
                          normal: 'FIXME',
                          low: 'TODO'
                archive(["sloccount.sc"])
                deleteDir()
            }
        }
    }]
}

def buildCheckReleaseNotes() {
    def stage_name = "check-release-notes"
    return [(stage_name): {
        maybeStage(stage_name, !isMaster()) {
            withDockerEnv(DOCKER_IMAGES.stretch) {
                sh "scripts/run_check_release_notes"
                deleteDir()
            }
        }
    }]
}

def buildIcheck() {
    def stage_name = "icheck"
    return [(stage_name): {
        stage(stage_name) {
            withDockerEnv(DOCKER_IMAGES.stretch) {
                sh "scripts/run_icheck"
                deleteDir()
            }
        }
    }]
}

def buildDoc() {
    def test_name = "doc"
    cmake_flags = [
        'BUILD_PDF': 'ON',
        'BUILD_FULL': 'OFF',
        'BUILD_SHARED': 'OFF',
        'BUILD_STATIC': 'OFF',
        'BUILD_TESTING': 'OFF'
    ]
    return [(test_name): {
        stage(test_name) {
            withDockerEnv(DOCKER_IMAGES.stretch_doc) {
                dir('build') {
                    deleteDir()
                    cmake(env.WORKSPACE, cmake_flags)
                    sh "make html latex man pdf"
                }

                def apib = "./doc/api_blueprints/snippet-sharing.apib"
                def api_doc_dir = "./build/API_DOC/restapi"
                sh "mkdir -p ${api_doc_dir}/${VERSION}"
                sh "cp ${apib} ${api_doc_dir}/${VERSION}/"
                apiary(apib, "${api_doc_dir}/${VERSION}/snippet-sharing.html")
                dir(api_doc_dir) {
                    sh "ln -s ${VERSION} current"
                }

                warnings parserConfigurations: [
                    [parserName: 'Doxygen', pattern: 'build/doc/doxygen.log']
                ]

                // TODO don't write to latest on PR's
                sshPublisher(
                    publishers: [
                        sshPublisherDesc(
                            configName: 'doc.libelektra.org',
                            transfers: [
                                sshTransfer(
                                    sourceFiles: 'build/doc/latex/*',
                                    removePrefix: 'build/doc/',
                                    remoteDirectory: 'api/latest'
                                ),
                                sshTransfer(
                                    sourceFiles: 'build/doc/man/*',
                                    removePrefix: 'build/doc/',
                                    remoteDirectory: 'api/latest'
                                ),
                                sshTransfer(
                                    sourceFiles: 'doc/help/*.html',
                                    removePrefix: 'doc/help/',
                                    remoteDirectory: 'help'
                                ),
                                sshTransfer(
                                    sourceFiles: 'build/API_DOC/*',
                                    removePrefix: 'build/API_DOC/'
                                )
                            ]
                        )
                    ],
                    verbose: true
                )
                deleteDir()
            }
        }
    }]
}

/* Helper to generate an asan enabled test */
def buildAndTestAsan(test_name, image, extra_cmake_flags = [:]) {
    def cmake_flags = CMAKE_FLAGS_BASE +
                      CMAKE_FLAGS_ASAN +
                      extra_cmake_flags
    def docker_opts = [DOCKER_OPTS.MOUNT_MIRROR, DOCKER_OPTS.PTRACE]
    return [(test_name): {
        stage(test_name) {
            withDockerEnv(image, docker_opts) {
                dir('build') {
                    deleteDir()
                    cmake(env.WORKSPACE, cmake_flags)
                    sh "make"
                    def llvm_symbolizer = sh(returnStdout: true,
                                             script: 'which llvm-symbolizer').trim()
                    withEnv(["ASAN_OPTIONS='symbolize=1'",
                             "ASAN_SYMBOLIZER_PATH=${llvm_symbolizer}"]){
                        ctest()
                    }
                }
            }
        }
    }]
}

/* Helper to generate a typical elektra test environment
 *   Builds elektra, depending on the contents of 'tests' it runs the
 *   corresponding test suites.
 * test_name: used to identify the test and name the stage
 * image: which docker image should be used
 * cmake_flags: which flags should be passed to cmake
 * tests: list of tests which should be run
 * extra_artifacts: which files should be additionally saved from the build
 */
def buildAndTest(test_name, image, extra_cmake_flags = [:],
                   tests = [], extra_artifacts = []) {
    def cmake_flags = CMAKE_FLAGS_BASE + extra_cmake_flags
    def artifacts = []
    if(tests) {
        artifacts.add("build/Testing/*/*.xml")
    }
    def test_coverage = cmake_flags.intersect(CMAKE_FLAGS_COVERAGE)
                                   .equals(CMAKE_FLAGS_COVERAGE)
    def test_mem = tests.contains(TEST.MEM)
    def test_nokdb = tests.contains(TEST.NOKDB)
    def test_all = tests.contains(TEST.ALL)
    def install = tests.contains(TEST.INSTALL)
    return [(test_name): {
        stage(test_name) {
            withDockerEnv(image) {
                try {
                    dir('build') {
                        deleteDir()
                        cmake(env.WORKSPACE, cmake_flags)
                        sh "make"
                        trackCoverage(test_coverage) {
                            if(test_all) {
                                ctest()
                            } else if(test_nokdb) {
                                cnokdbtest()
                            }
                            if(test_mem) {
                                cmemcheck(test_nokdb)
                            }
                        }
                        if(install) {
                            sh 'make install'
                        }
                    }
                    if(install) {
                        sh '''\
export LD_LIBRARY_PATH=${WORKSPACE}/system/lib:$LD_LIBRARY_PATH
export PATH=${WORKSPACE}/system/bin:$PATH
export DBUS_SESSION_BUS_ADDRESS=`dbus-daemon --session --fork --print-address`
export LUA_CPATH="${WORKSPACE}/system/lib/lua/5.2/?.so;"
kdb run_all
kill `pidof dbus-daemon`
'''
                    }
                } catch(e) {
                    // rethrow to mark as failed
                    throw e
                } finally {
                    /* Warnings plugin overwrites each other, disable for now
                    warnings canRunOnFailed: true, consoleParsers: [
                        [parserName: 'GNU Make + GNU C Compiler (gcc)']
                    ]
                    */
                    archive(artifacts)
                    if(test_coverage) {
                        publishCoverage()
                    }
                    if(test_mem || test_nokdb || test_all) {
                        xunitUpload()
                    }
                    deleteDir()
                }
            }
        }
    }]
}

/* Generate Stages that build and deploy artifacts
 */
def generateArtifactStages() {
    def tasks = [:]
    tasks << buildPackageDebianStretch()
    tasks << buildHomepage()
    return tasks
}

def buildPackageDebianStretch() {
    return withDockerEnv(DOCKER_IMAGES.stretch, [DOCKER_OPTS.MOUNT_MIRROR]) {
        withCredentials([file(credentialsId: 'jenkins-key', variable: 'KEY'),
                         file(credentialsId: 'jenkins-secret-key', variable: 'SKEY')]) {
            sh "gpg --import $KEY"
            sh "gpg --import $SKEY"
        }
        withEnv(["DEBSIGN_PROGRAM=gpg",
                 "DEBFULLNAME=Jenkins (User for Elektra automated build system)",
                 "DEBEMAIL=autobuilder@libelektra.org"]) {
            sh "rm -R ./*"
            def target_dir="./libelektra"
            checkout scm: [
                $class: 'GitSCM',
                branches: scm.branches,
                extensions: scm.extensions + [
                    [$class: 'PerBuildTag'],
                    [$class: 'RelativeTargetDirectory',
                     relativeTargetDir: target_dir]
                ],
                userRemoteConfigs: scm.userRemoteConfigs
            ]
            dir(target_dir) {
                sh "git checkout -B temp"
                sh "git tag -f $VERSION"

                sh "git checkout -B debian origin/debian"
                sh "git merge --no-ff -m 'merge $VERSION' temp"

                sh "dch -l '.$BUILD_NUMBER' 'auto build'"
                sh "git commit -am 'auto build $VERSION'"

                sh "gbp buildpackage -sa"
            }
        }
    }
}

def deployHomepage() {
    node("frontend") {
        docker.withRegistry("https://${registry}",
                            'docker-hub-elektra-jenkins') {
            def backend_name = "elektra-backend"
            def frontend_name = "elektra-frontend"
            def backend = docker.image(DOCKER_IMAGES.homepage_backend.id)
            def frontend = docker.image(DOCKER_IMAGES.homepage_frontend.id)
            backend.pull()
            frontend.pull()

            sh "docker stop -t 5 ${backend_name} || /bin/true"
            sh "docker rm ${backend_name} || /bin/true"
            backend.run("""\
                -e VIRTUAL_HOST=restapi.libelektra.org \
                -e LETSENCRYPT_HOST=restapi.libelektra.org \
                -e LETSENCRYPT_EMAIL=jenkins@hub.libelektra.org \
                --name ${backend_name} \
                --network=frontend_default \
                --restart=always"""
            )

            sh "docker stop -t 5 ${frontend_name} || /bin/true"
            sh "docker rm ${frontend_name} || /bin/true"
            frontend.run("""\
                -e VIRTUAL_HOST=www.libelektra.org \
                -e LETSENCRYPT_HOST=www.libelektra.org \
                -e LETSENCRYPT_EMAIL=jenkins@hub.libelektra.org \
                --name ${frontend_name} \
                --network=frontend_default \
                --restart=always"""
            )
        }
    }
}

def buildHomepage() {
    def homepage_tasks = [:]
    homepage_tasks << buildImageStage(DOCKER_IMAGES.homepage_frontend)
    homepage_tasks << buildImageStage(DOCKER_IMAGES.homepage_backend)
    return homepage_tasks
}

/*****************************************************************************
 * Define helper functions
 *****************************************************************************/

/* Archives files located in paths
 *
 * Automatically prefixes with the current STAGE_NAME to identify where the
 * file was created.
 * @param paths List of paths to be archived
 */
def archive(paths) {
    echo "Start archivation"
    if (paths) {
        def prefix = "artifacts/"
        def dest = "${prefix}${env.STAGE_NAME}/"
        sh "mkdir -p ${dest}"
        paths.each { path ->
            sh "cp -v ${path} ${dest} || true"
        }
        archiveArtifacts artifacts: "${prefix}**", fingerprint: true
    } else {
        echo "No Artifacts to archive"
    }
    echo "Finish archivation"
}


/* Run cmake
 * @param directory Basedir for cmake
 * @param args_map Map of arguments for cmake
 */
def cmake(String directory, Map args_map) {
    def args_str = ""
    args_map.each { key, value ->
        args_str += "-D$key=\"$value\" "
    }
    sh("cmake $args_str $directory")
}

/* Publishes coverage reports
 */
def publishCoverage() {
    echo "Start publication of coverage data"
    def uploadDir = "coverage/${env.BRANCH_NAME}/${env.STAGE_NAME}"

    sh "mkdir -p ${uploadDir}"
    sh "mv -v -T build/coverage ${uploadDir}"

    sshPublisher(
        publishers: [
            sshPublisherDesc(
                configName: 'doc.libelektra.org',
                transfers: [
                    sshTransfer(
                        sourceFiles: uploadDir + '/**',
                    )
                ]
            )
        ],
        verbose: true
    )
    echo "Finish publication of coverage data"
}

/* Get the current users uid
 */
def getUid() {
    return sh(returnStdout: true, script: 'id -u').trim()
}


/* Get the current users gid
 */
def getGid() {
    return sh(returnStdout: true, script: 'id -g').trim()
}

/* Track coverage
 *
 * Tracks coverage of commands executed in the passed closure if do_track
 * evaluates to true.
 * @param do_track If true track coverage
 * @param cl A closure that this function wraps around
 */
def trackCoverage(do_track, cl) {
    if(do_track) {
        sh 'make coverage-start'
    }
    cl()
    if(do_track) {
        sh 'make coverage-stop'
        sh 'make coverage-genhtml'
    }
}

/* Run the passed closure in a docker environment
 *
 * Automatically takes care of docker registry authentication,
 * selecting a docker capable node,
 * checkout of scm and setting of useful Environment variables
 * @param image Docker image that should be used
 * @param opts List of DOCKER_OPTS that should be passed to docker
 * @param cl A closure that should be run inside the docker image
 */
def withDockerEnv(image, opts=[], cl) {
    def docker_args = ""
    if (opts.contains(DOCKER_OPTS.MOUNT_MIRROR)) {
        docker_args += "-v ${env.HOME}/git_mirrors:/home/jenkins/git_mirrors "
    }
    if (opts.contains(DOCKER_OPTS.PTRACE)) {
        docker_args += "--cap-add SYS_PTRACE "
    }
    node(docker_node_label) {
        docker.withRegistry("https://${registry}",
                            'docker-hub-elektra-jenkins') {
            timeout(activity: true, time: 5, unit: 'MINUTES') {
                def cpu_count = cpuCount()
                withEnv(["MAKEFLAGS='-j${cpu_count+2} -l${cpu_count*2}'",
                         "CTEST_PARALLEL_LEVEL='${cpu_count+2}'"]) {
                    echo "Starting ${env.STAGE_NAME} on ${env.NODE_NAME}"
                    checkout scm
                    docker.image(image.id)
                          .inside(docker_args) { cl() }
                }
            }
        }
    }
}

/* Get cpu count
 */
def cpuCount() {
    return sh(returnStdout: true,
              script: 'grep -c ^processor /proc/cpuinfo').trim() as Integer
}

/* Run ctest with appropriate env variables
 * @param target What target to pass to ctest
 */
def ctest(target = "Test") {
    sh """ctest -j ${env.CTEST_PARALLEL_LEVEL} --force-new-ctest-process \
            --output-on-failure --no-compress-output -T ${target}"""
}

/* Helper for ctest to run MemCheck without memleak tagged tests
 * @param kdbtests If true run tests tagged as kdbtests
 */
def cmemcheck(kdbtests) {
    if(kdbtests) {
        ctest("MemCheck -LE memleak")
    } else {
        ctest("MemCheck -LE memleak||kdbtests")
    }
}

/* Helper for ctest to run tests without tests tagged as kdbtests
 */
def cnokdbtest() {
    ctest("Test -LE kdbtests")
}

/* Uploads ctest results
 */
def xunitUpload() {
    step([$class: 'XUnitBuilder',
          thresholds: [
            [$class: 'SkippedThreshold', failureThreshold: '0'],
            [$class: 'FailedThreshold', failureThreshold: '0']
          ],
          tools: [
            [$class: 'CTestType',
                pattern: 'build/Testing/**/*.xml']
        ]
    ])
}

/* Create a new Docker Image Description
 *
 * @param name Name of the image, will be extended with registry, a common
 *             prefix and a tag
 * @param tagFun Closure describing how the tag should be formatted
 * @param context Context for the docker build
 * @param file Path to Dockerfile
 * @param autobuild If it should be automatically build at the start of the
 *                  Jenkins run
 */
def createDockerImageDesc(name, idFun, context, file, autobuild=true) {
    def prefix = 'build-elektra'
    def full_name = "${registry}/${prefix}-${name}"
    def map = [
        name: full_name,
        context: context,
        file: file,
        autobuild: autobuild,
        exists: false
    ]
    return idFun(map)
}

/* Build image ID of docker images used for tests
 *
 * We use identifiers in the form of name:yyyyMM-hash
 * The hash is build from reading the Dockerfile. Hence it needs to be
 * checked out before it can be calculated.
 * @param image_map Map identifying an docker image (see DOCKER_IMAGES)
 */
def idTesting(image_map) {
    def cs = checksum(image_map.file)
    def dateString = dateFormatter(NOW)
    image_map.id = "${image_map.name}:${dateString}-${cs}"
    return image_map
}

/* Build id for homepage
 *
 * @param image_map Map identifying an docker image
 */
def idHomepage(image_map) {
    image_map.id = "${image_map.name}:${BRANCH_NAME}_${BUILD_NUMBER}"
    return image_map
}

/* Generate the checksum of a file
 * @param file File to generate a checksum for
 */
def checksum(file) {
    // Used to identify if a Dockerfile changed
    // TODO expand to use more than one file if Dockerfile ever depends on
    //      external files
    return sh(returnStdout: true,
              script: "cat $file | sha256sum | dd bs=1 count=64 status=none")
           .trim()
}

/* Generate a Stage
 *
 * If `expression` evaluates to TRUE, a stage(`name`) with `body` is run
 * @param name Name of the stage
 * @param expression If True, run body
 * @param body Closure representing stage body
 */
def maybeStage(String name, boolean expression, Closure body) {
    if(expression) {
        stage(name, body)
    } else {
        stage(name) {
            echo "Stage skipped: ${name}"
        }
    }
}

/* Format the date input
 * @param date Date to format
 */
def dateFormatter(date) {
    df = new SimpleDateFormat("yyyyMM")
    return df.format(date)
}

/* Returns True if we are on the master branch
 */
def isMaster() {
    return env.BRANCH_NAME=="master"
}

/* Publishes all files necessary for hosting a debian package
 * @param remote where the repository is located
 */
def publishDebianPackages(remote="a7") {
    if(isMaster()) {
        def remotedir = 'compose/frontend/volumes/incoming'
        sshPublisher(
          publishers: [
            sshPublisherDesc(
              configName: remote,
              transfers: [
                sshTransfer(
                  sourceFiles: '*.deb',
                  remoteDirectory: remotedir
                ),
                sshTransfer(
                  sourceFiles: '*.build',
                  remoteDirectory: remotedir
                ),
                sshTransfer(
                  sourceFiles: '*.buildinfo',
                  remoteDirectory: remotedir
                ),
                sshTransfer(
                  sourceFiles: '*.dsc',
                  remoteDirectory: remotedir
                ),
                sshTransfer(
                  sourceFiles: '*.tar.xz',
                  remoteDirectory: remotedir
                ),
                sshTransfer(
                  sourceFiles: '*.tar.gz',
                  remoteDirectory: remotedir
                ),
                sshTransfer(
                  sourceFiles: '*.changes',
                  remoteDirectory: remotedir
                )
              ]
            )
          ],
          verbose: true,
          failOnError: true
        )
    } else {
        echo "Skipping package publish because we are not on master"
    }
}

/* Run apiary
 * @param input Input file (.apib)
 * @param output Output file (.html)
 */
def apiary(input, output) {
    sh "apiary preview --path=${input} --output=${output}"
}

def abortPreviousRun() {
    def exec = currentBuild
               ?.rawBuild
               ?.getPreviousBuildInProgress()
               ?.getExecutor()
    if(exec) {
        exec.interrupt(
            Result.ABORTED,
            new CauseOfInterruption.UserInterruption(
              "Aborted by Build#${currentBuild.number}"
            )
        )
    }
}
